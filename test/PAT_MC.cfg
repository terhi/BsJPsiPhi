[CRAB]

jobtype = cmssw
#use_server =  1
use_server =  0
scheduler = remoteGlidein

[CMSSW]

###### TARKISTA SEURAAVAT ASIAT #####
# 1. datasetpath on oikea
# 2. datasetpathissa maariteltya datasettia vastaa oikea JSON
# 3. data tallentuu haluttuun kansioon
# 4. output tiedoston nimi on oikea
# 5. output tiedoston nimi on sama kuin JPsiPhiPAT_data_38X.py tiedostossa
# 6. JPsiPhiPAT_data_38X.py tiedostossa maaritelty global tag on datasetin global tag
# 7. JPsiPhiPAT_data_38X.py ei ole kommentoimattimia datatiedostoja ja ett√§ eventtien maara -1

#dataset is used as Bs muon tagging dataset,
#datasetpath = /BsToJPsiPhi_2K2MuPtEtaFilter_8TeV-pythia6-evtgen/Summer12_DR53X-PU_S10_START53_V7A-v1/AODSIM
#datasetpath = /BsToJpsiPhiV2_BFilter_TuneZ2star_8TeV-pythia6-evtgen/Summer12_DR53X-PU_RD2_START53_V19F-v3/AODSIM

#this dataset used as Bplus muon tagging dataset (bad one)
#datasetpath = /BuToJPsiK_K2MuFilter_8TeV-pythia6-evtgen/Summer12_DR53X-PU_S10_START53_V7A-v1/AODSIM

#Bplus muon tagging dataset
datasetpath = /BuToJPsiK_K2MuPtEtaEtaFilter_8TeV-pythia6-evtgen/Summer12_DR53X-PU_S10_START53_V7A-v2/AODSIM

#Bd dataset 
#datasetpath =/BdToJpsiKstar_EtaPtFilter_8TeV-pythia6-evtgen/Summer12_DR53X-PU_S10_START53_V7C-v1/AODSIM

#Newer Bd dataset 
#datasetpath = /BdToKstarJPsi_EtaPtFilter_8TeV-pythia6-evtgen/Summer12_DR53X-PU_RD2_START53_V19F-v1/AODSIM



############# Giacomo's datasets ########### 
#datasetpath = /BsToJpsiPhiV2_BFilter_TuneZ2star_8TeV-pythia6-evtgen/Summer12_DR53X-PU_RD2_START53_V19F-v3/AODSIM

#datasetpath = /JPsiToMuMu_2MuPtEtaFilter_tuneD6T_8TeV-pythia6-evtgen/Summer12_DR53X-PU_S10_START53_V7A-v2/AODSIM

###############

### The ParameterSet you want to use
#pset = JPsiPhiPAT_MC_38X.py
pset = MC.py

#use_parent = 1
#get_edm_output = 1


### Splitting parameters:
### Total number of events to be accessed: -1 means all
total_number_of_events = 700000
#total_number_of_events = 25000

### Number of events to be processed per job
# events_per_job = 10
### Number of jobs
#number_of_jobs = 1000
events_per_job= 5000

### The output files produced by your application (comma separated list)
output_file = BuToJPsiK.root


[USER]

## to have back the job executable output into UI (return_data= 1)
return_data = 0
email=terhi.jarvinen@cern.ch

### COPY JOB OUTPUT INTO A SE ###
copy_data = 1

### if copy_data = 1 ###
storage_element = madhatter.csc.fi
storage_path = /srm/managerv2?SFN=/pnfs/csc.fi/data/cms/store/

#----------------------------------------------------------------------------------------------------------------------------
logdir=/tmp/terhi/crabFolder
#user_remote_dir = /user/t/terhi/BsMCCorr
user_remote_dir = /user/terhi/BsBptest
#----------------------------------------------------------------------------------------------------------------------------


## IMPORTANT create the dir in castor (e.g.)
##           add the permission to it or all the jobs will crash :-)
#rfmkdir /castor/cern.ch/user/u/username/subdir 
#rfchmod +775 /castor/cern.ch/user/u/username/subdir

Check_user_remote_dir = 0


#################################
####### JOB MONITORING  ### #####
#################################

### Use central BOSS DB instead of one for each task: the DB must be already been setup!
use_central_bossDB = 0

### Use Boss RealTime monitoring
use_boss_rt = 1 


[GRID]
################################
###### EDG specific stuff ######
################################

# LCG middleware version installed on testbed
lcg_version = 2


#remove_default_blacklist=1

## to change the CMS-broker RB. The ones available for CMS are "CERN" and "CNAF": the configuration
## files needed to change the broker will be automatically downloaded from CRAB web page. If the
## files are already present on the working directory they will be used. 
rb = CERN

## CMS myproxy server, to proxy delegation
proxy_server = myproxy.cern.ch 

## Role in VOMS
#role = superman

## Group in VOMS
#group = superheros

## If you don't want CRAB to check your proxy
#dont_check_proxy = 1

## to add other requirements to jdl file, as example the Operating System
#requirements = (other.GlueHostOperatingSystemName == "RedHat")

## to add other parameters to jdl file: comma separated list, each item _must_
## be complete, including the closing ";"
additional_jdl_parameters = AllowZippedISB = false;

## cpu time and wall_clock_time(=real time) in minutes. Written into the jdl file
#max_cpu_time = 60
#max_wall_clock_time = 60

## SE Black List: all the storage elements (SE) containing the following strings (comma
## separated list) will not be considered for submission.
## for discovery, please use http://cmslcgco01.cern.ch:8001/
#se_black_list = helsinki.fi 
#se_black_list = dgc-grid-50.brunel.ac.uk, ppgrid1.rhul.ac.uk, t2-srm-02.lnl.infn.it, cmsdcache.pi.infn.it, lcg02.ciemat.es, lcg002.ihep.ac.cn

#se_black_list = T2_FI_HIP

## SE White List: only the storage elements (SE) containing the following strings (comma
## separated list) will be considered for submission.
## for discovery, please use http://cmslcgco01.cern.ch:8001/
#se_white_list = infn,cnaf,cscs,polgrid,desy,fzk,aachen,warsaw,T2_CN_Beijing
#se_white_list = cnaf

## CE Black List: all the CE whose name contains the following strings (comma
## separated list) will not be considered for submission.
## Use the dns domain (eg fnal, cern, ifae, fzk, cnaf, lnl,....)
#ce_black_list = T2_US_Purdue
#ce_black_list = ametisti


## CE White List: only the CE whose name contains the following strings (comma
## separated list) will be considered for submission.
## Use the dns domain (eg fnal, cern, ifae, fzk, cnaf, lnl,....)
#ce_white_list = cnaf
#ce_white_list = infn,cnaf,cscs,polgrid,desy,fzk,aachen,warsaw,T2_CN_Beijing


## fields written into jdl
virtual_organization = cms

## number or retry count
retry_count = 4

## LFC catalog parameters
lcg_catalog_type = lfc
lfc_host = lfc-cms-test.cern.ch
lfc_home = /grid/cms

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

